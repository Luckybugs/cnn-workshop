{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.constraints import maxnorm\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import concatenate, add\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import numpy as np \n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import TrainingMonitor\n",
    "from helpers import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = \"../output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_train = h5py.File(\"../input/datasets/cifar_rgbmean_train.hdf5\")\n",
    "db_test = h5py.File(\"../input/datasets/cifar_rgbmean_test.hdf5\")\n",
    "\n",
    "x_train_rgbmean = db_train[\"images\"][:].astype('float32')\n",
    "x_test_rgbmean = db_test[\"images\"][:].astype('float32')\n",
    "\n",
    "mean = np.mean(x_train_rgbmean, axis=0)\n",
    "x_train_rgbmean -= mean\n",
    "x_test_rgbmean -= mean\n",
    "\n",
    "y_train_rgbmean = db_train[\"labels\"][:]\n",
    "y_test_rgbmean = db_test[\"labels\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RESNET:\n",
    "    @staticmethod \n",
    "    def residual_module(data, num_filter, stride, red=False, reg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
    "        shortcut = data\n",
    "        \n",
    "        act1 = Activation(\"relu\")(data)\n",
    "        bn1 = BatchNormalization(axis=-1, epsilon=bnEps, momentum=bnMom)(act1)\n",
    "        conv1 = Conv2D(int(num_filter * 0.25), (1, 1), use_bias=False, kernel_regularizer=l2(reg))(bn1)\n",
    "        \n",
    "        act2 = Activation(\"relu\")(conv1)\n",
    "        bn2 = BatchNormalization(axis=-1, epsilon=bnEps, momentum=bnMom)(act2)\n",
    "        conv2 = Conv2D(int(num_filter * 0.25), (3, 3), strides=stride, padding=\"same\", use_bias=False, \n",
    "                       kernel_regularizer=l2(reg))(bn2)\n",
    "        \n",
    "        bn3 = BatchNormalization(axis=-1, epsilon=bnEps, momentum=bnMom)(conv2)\n",
    "        conv3 = Conv2D(num_filter, (1, 1), use_bias=False, kernel_regularizer=l2(reg))(bn3)\n",
    "        \n",
    "        if red:\n",
    "            shortcut = Conv2D(num_filter, 1, strides=stride, use_bias=False, kernel_regularizer=l2(reg))(act1)\n",
    "                    \n",
    "        x = add([conv3, shortcut])\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=-1, epsilon=bnEps, momentum=bnMom)(x)\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def build(stages, filters, reg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
    "        input_tensor = Input(shape=x_train_rgbmean.shape[1:])\n",
    "        \n",
    "        x = BatchNormalization(axis=-1, epsilon=bnEps, momentum=bnMom)(input_tensor)\n",
    "        x = Conv2D(filters[0], (3, 3), use_bias=False, padding=\"same\", kernel_regularizer=l2(reg))(x)\n",
    "        \n",
    "        for i in range(0, len(stages)): \n",
    "            stride = (1, 1) if i == 0 else (2, 2)\n",
    "            x = RESNET.residual_module(x, filters[i + 1], stride, red=True, bnEps=bnEps, bnMom=bnMom)\n",
    "            for j in range(0, stages[i] - 1): \n",
    "                x = RESNET.residual_module(x, filters[i + 1], (1, 1), bnEps=bnEps, bnMom=bnMom)\n",
    "        \n",
    "        x = AveragePooling2D((8, 8))(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(10, kernel_regularizer=l2(reg), kernel_constraint=maxnorm(3))(x)\n",
    "        x = Activation(\"softmax\")(x)\n",
    "            \n",
    "        model = Model(input_tensor, x, name=\"resnet\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = RESNET.build((2, 2, 2), (32, 32, 64, 64), reg=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 32, 32, 3)    12          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 32, 32, 32)   864         batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 32, 32, 32)   0           conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 32, 32, 32)   128         activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 32, 32, 8)    256         batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 32, 32, 8)    0           conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 32, 32, 8)    32          activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 32, 32, 8)    576         batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 32, 32, 8)    32          conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 32, 32, 32)   256         batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 32, 32, 32)   1024        activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 32, 32, 32)   0           conv2d_124[0][0]                 \n",
      "                                                                 conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 32, 32, 32)   0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 32, 32, 32)   128         activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 32, 32, 32)   0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 32, 32, 32)   128         activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 32, 32, 8)    256         batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 32, 32, 8)    0           conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 32, 32, 8)    32          activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 32, 32, 8)    576         batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 32, 32, 8)    32          conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 32, 32, 32)   256         batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 32, 32, 32)   0           conv2d_128[0][0]                 \n",
      "                                                                 batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 32, 32, 32)   0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 32, 32, 32)   128         activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 32, 32, 32)   0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 32, 32, 32)   128         activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 32, 32, 16)   512         batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 32, 32, 16)   0           conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 32, 32, 16)   64          activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 16, 16, 16)   2304        batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 16, 16, 16)   64          conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 16, 16, 64)   1024        batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 16, 16, 64)   2048        activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 16, 16, 64)   0           conv2d_131[0][0]                 \n",
      "                                                                 conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 16, 16, 64)   0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 16, 16, 64)   256         activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 16, 16, 64)   0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 16, 16, 64)   256         activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 16, 16, 16)   1024        batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 16, 16, 16)   0           conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 16, 16, 16)   64          activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 16, 16, 16)   2304        batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 16, 16, 16)   64          conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 16, 16, 64)   1024        batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 16, 16, 64)   0           conv2d_135[0][0]                 \n",
      "                                                                 batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 16, 16, 64)   0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 16, 16, 64)   256         activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 16, 16, 64)   0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 16, 16, 64)   256         activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 16, 16, 16)   1024        batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 16, 16, 16)   0           conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 16, 16, 16)   64          activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 8, 8, 16)     2304        batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 8, 8, 16)     64          conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 8, 8, 64)     1024        batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 8, 8, 64)     4096        activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 8, 8, 64)     0           conv2d_138[0][0]                 \n",
      "                                                                 conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 8, 8, 64)     0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 8, 8, 64)     256         activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 8, 8, 64)     0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 8, 8, 64)     256         activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 8, 8, 16)     1024        batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 8, 8, 16)     0           conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 8, 8, 16)     64          activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 8, 8, 16)     2304        batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 8, 8, 16)     64          conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 8, 8, 64)     1024        batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 8, 8, 64)     0           conv2d_142[0][0]                 \n",
      "                                                                 batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 8, 8, 64)     0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 8, 8, 64)     256         activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 1, 1, 64)     0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 64)           0           average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           650         flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 10)           0           dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 30,838\n",
      "Trainable params: 29,296\n",
      "Non-trainable params: 1,542\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tInputLayer\n",
      "1\tBatchNormalization\n",
      "2\tConv2D\n",
      "3\tActivation\n",
      "4\tBatchNormalization\n",
      "5\tConv2D\n",
      "6\tActivation\n",
      "7\tBatchNormalization\n",
      "8\tConv2D\n",
      "9\tBatchNormalization\n",
      "10\tConv2D\n",
      "11\tConv2D\n",
      "12\tAdd\n",
      "13\tActivation\n",
      "14\tBatchNormalization\n",
      "15\tActivation\n",
      "16\tBatchNormalization\n",
      "17\tConv2D\n",
      "18\tActivation\n",
      "19\tBatchNormalization\n",
      "20\tConv2D\n",
      "21\tBatchNormalization\n",
      "22\tConv2D\n",
      "23\tAdd\n",
      "24\tActivation\n",
      "25\tBatchNormalization\n",
      "26\tActivation\n",
      "27\tBatchNormalization\n",
      "28\tConv2D\n",
      "29\tActivation\n",
      "30\tBatchNormalization\n",
      "31\tConv2D\n",
      "32\tBatchNormalization\n",
      "33\tConv2D\n",
      "34\tConv2D\n",
      "35\tAdd\n",
      "36\tActivation\n",
      "37\tBatchNormalization\n",
      "38\tActivation\n",
      "39\tBatchNormalization\n",
      "40\tConv2D\n",
      "41\tActivation\n",
      "42\tBatchNormalization\n",
      "43\tConv2D\n",
      "44\tBatchNormalization\n",
      "45\tConv2D\n",
      "46\tAdd\n",
      "47\tActivation\n",
      "48\tBatchNormalization\n",
      "49\tActivation\n",
      "50\tBatchNormalization\n",
      "51\tConv2D\n",
      "52\tActivation\n",
      "53\tBatchNormalization\n",
      "54\tConv2D\n",
      "55\tBatchNormalization\n",
      "56\tConv2D\n",
      "57\tConv2D\n",
      "58\tAdd\n",
      "59\tActivation\n",
      "60\tBatchNormalization\n",
      "61\tActivation\n",
      "62\tBatchNormalization\n",
      "63\tConv2D\n",
      "64\tActivation\n",
      "65\tBatchNormalization\n",
      "66\tConv2D\n",
      "67\tBatchNormalization\n",
      "68\tConv2D\n",
      "69\tAdd\n",
      "70\tActivation\n",
      "71\tBatchNormalization\n",
      "72\tAveragePooling2D\n",
      "73\tFlatten\n",
      "74\tDense\n",
      "75\tActivation\n"
     ]
    }
   ],
   "source": [
    "for (i, layer) in enumerate(model.layers): \n",
    "    print(\"{}\\t{}\".format(i, layer.__class__.__name__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='models/baseline-resenet.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2984\n"
     ]
    }
   ],
   "source": [
    "#filepath=output_path + \"progress/inception-weights-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "print(os.getpid())\n",
    "filepath=output_path + \"progress/resnet-weights-best.hdf5\"\n",
    "MC = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "figPath = os.path.sep.join([output_path, \"monitor/{}.png\".format(os.getpid())])\n",
    "jsonPath = os.path.sep.join([output_path, \"monitor/{}.json\".format(os.getpid())])\n",
    "TM = TrainingMonitor(figPath, jsonPath=jsonPath, startAt=0)\n",
    "\n",
    "RLR = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [MC, TM, RLR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33500 samples, validate on 16500 samples\n",
      "Epoch 1/10\n",
      "33500/33500 [==============================] - 63s 2ms/step - loss: 0.3050 - acc: 0.9045 - val_loss: 0.2720 - val_acc: 0.9112\n",
      "Epoch 2/10\n",
      "33500/33500 [==============================] - 50s 1ms/step - loss: 0.2550 - acc: 0.9157 - val_loss: 0.2410 - val_acc: 0.9191\n",
      "Epoch 3/10\n",
      "33500/33500 [==============================] - 50s 1ms/step - loss: 0.2304 - acc: 0.9236 - val_loss: 0.2249 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      "33500/33500 [==============================] - 50s 2ms/step - loss: 0.2133 - acc: 0.9295 - val_loss: 0.2109 - val_acc: 0.9308\n",
      "Epoch 5/10\n",
      "33500/33500 [==============================] - 51s 2ms/step - loss: 0.2022 - acc: 0.9332 - val_loss: 0.2022 - val_acc: 0.9335\n",
      "Epoch 6/10\n",
      "33500/33500 [==============================] - 50s 1ms/step - loss: 0.1927 - acc: 0.9366 - val_loss: 0.2028 - val_acc: 0.9326\n",
      "Epoch 7/10\n",
      "33500/33500 [==============================] - 50s 1ms/step - loss: 0.1858 - acc: 0.9391 - val_loss: 0.1937 - val_acc: 0.9357\n",
      "Epoch 8/10\n",
      "33500/33500 [==============================] - 50s 2ms/step - loss: 0.1797 - acc: 0.9411 - val_loss: 0.1876 - val_acc: 0.9380\n",
      "Epoch 9/10\n",
      "33500/33500 [==============================] - 51s 2ms/step - loss: 0.1743 - acc: 0.9429 - val_loss: 0.1831 - val_acc: 0.9394\n",
      "Epoch 10/10\n",
      "33500/33500 [==============================] - 50s 1ms/step - loss: 0.1705 - acc: 0.9440 - val_loss: 0.1834 - val_acc: 0.9392\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_rgbmean, y_train_rgbmean,\n",
    "            batch_size=64,\n",
    "            epochs=10,\n",
    "            validation_split=0.33,\n",
    "            shuffle=\"batch\",\n",
    "            callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 94.48%; Val: 94.16%; Test: 94.02%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test_rgbmean, y_test_rgbmean, verbose=0)\n",
    "print(\"Train: %.2f%%; Val: %.2f%%; Test: %.2f%%\" % \n",
    "      (np.max(history.history['acc'])*100, np.max(history.history['val_acc'])*100, scores[1]*100)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(output_path + \"cifar_model_resnet_94.02.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(output_path + \"cifar_weight_resnet_94.02.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
