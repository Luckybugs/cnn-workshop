{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.constraints import maxnorm\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import numpy as np \n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import TrainingMonitor\n",
    "from helpers import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = \"../output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_train = h5py.File(\"../input/datasets/cifar_rgbmean_train.hdf5\")\n",
    "db_test = h5py.File(\"../input/datasets/cifar_rgbmean_test.hdf5\")\n",
    "\n",
    "x_train_rgbmean = db_train[\"images\"][:].astype('float32')\n",
    "x_test_rgbmean = db_test[\"images\"][:].astype('float32')\n",
    "\n",
    "mean = np.mean(x_train_rgbmean, axis=0)\n",
    "x_train_rgbmean -= mean\n",
    "x_test_rgbmean -= mean\n",
    "\n",
    "y_train_rgbmean = db_train[\"labels\"][:]\n",
    "y_test_rgbmean = db_test[\"labels\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class INCEPTION:\n",
    "    @staticmethod\n",
    "    def conv_module(x, num_filter, size_filter, stride, reg, name=None):\n",
    "        (convName, bnName, actName) = (None, None, None)\n",
    "        if name is not None:\n",
    "            convName = name + \"_conv\"\n",
    "            bnName = name + \"_bn\"\n",
    "            actName = name + \"_act\"\n",
    "            \n",
    "        x = Conv2D(num_filter, size_filter, strides=stride, padding=\"same\", kernel_regularizer=l2(reg), name=convName)(x)\n",
    "        x = Activation(\"relu\", name=actName)(x)\n",
    "        x = BatchNormalization(axis=-1, name=bnName)(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def inception_module(x, num1x1, num3x3Reduce, num3x3, num5x5Reduce, num5x5, num1x1Proj, reg, stage):\n",
    "\n",
    "        first = INCEPTION.conv_module(x, num1x1, 1, 1, reg, name=stage + \"_1x1\")\n",
    "\n",
    "        second = INCEPTION.conv_module(x, num3x3Reduce, 1, 1, reg, name=stage + \"_3x3_1\")\n",
    "        second = INCEPTION.conv_module(second, num3x3, 3, 1, reg, name=stage + \"_3x3_2\")\n",
    "\n",
    "        third = INCEPTION.conv_module(x, num5x5Reduce, 1, 1, reg, name=stage + \"_5x5_1\")\n",
    "        third = INCEPTION.conv_module(third, num5x5, 5, 1, reg, name=stage + \"_5x5_2\")\n",
    "\n",
    "        fourth = MaxPooling2D(3, strides=1, padding=\"same\", name=stage + \"_pool_1\")(x)\n",
    "        fourth = INCEPTION.conv_module(fourth, num1x1Proj, 1, 1, reg, name=stage + \"_pool_2\")\n",
    "\n",
    "        x = concatenate([first, second, third, fourth], axis=-1, name=stage + \"_mixed\")\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def build(include_top=True, reg=0.0005):\n",
    "        inputs = Input(shape=x_train_rgbmean.shape[1:])\n",
    "        \n",
    "        x = INCEPTION.inception_module(inputs, 32, 32, 32, 16, 16, 32, reg, \"block1\")\n",
    "        x = INCEPTION.inception_module(x, 64, 64, 64, 32, 32, 64, reg, \"block2\")\n",
    "        x = INCEPTION.inception_module(x, 64, 64, 64, 32, 32, 64, reg, \"block3\")\n",
    "        \n",
    "        if include_top:\n",
    "            x = AveragePooling2D((8, 8))(x)\n",
    "            x = Dropout(0.5, name=\"do\")(x)\n",
    "            x = Flatten(name=\"flatten\")(x)\n",
    "            x = Dense(10, kernel_regularizer=l2(reg), name=\"labels\")(x)\n",
    "            x = Activation(\"softmax\", name=\"softmax\")(x)\n",
    "            \n",
    "        model = Model(inputs, x)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = INCEPTION.build(include_top=True, reg=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9a7881f870d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='models/baseline-inception-v1.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8916\n"
     ]
    }
   ],
   "source": [
    "#filepath=output_path + \"progress/inception-weights-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "print(os.getpid())\n",
    "filepath=output_path + \"progress/inception-weights-best.hdf5\"\n",
    "MC = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "figPath = os.path.sep.join([output_path, \"monitor/{}.png\".format(os.getpid())])\n",
    "jsonPath = os.path.sep.join([output_path, \"monitor/{}.json\".format(os.getpid())])\n",
    "TM = TrainingMonitor(figPath, jsonPath=jsonPath, startAt=5)\n",
    "\n",
    "RLR = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [MC, TM, RLR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33500 samples, validate on 16500 samples\n",
      "Epoch 1/5\n",
      "33500/33500 [==============================] - 95s 3ms/step - loss: 0.1813 - acc: 0.9473 - val_loss: 0.1882 - val_acc: 0.9443\n",
      "Epoch 2/5\n",
      "33500/33500 [==============================] - 95s 3ms/step - loss: 0.1766 - acc: 0.9490 - val_loss: 0.1799 - val_acc: 0.9472\n",
      "Epoch 3/5\n",
      "33500/33500 [==============================] - 95s 3ms/step - loss: 0.1743 - acc: 0.9501 - val_loss: 0.1861 - val_acc: 0.9464\n",
      "Epoch 4/5\n",
      "33500/33500 [==============================] - 95s 3ms/step - loss: 0.1714 - acc: 0.9516 - val_loss: 0.1843 - val_acc: 0.9467\n",
      "Epoch 5/5\n",
      "33500/33500 [==============================] - 95s 3ms/step - loss: 0.1695 - acc: 0.9522 - val_loss: 0.1747 - val_acc: 0.9503\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_rgbmean, y_train_rgbmean,\n",
    "            batch_size=64,\n",
    "            epochs=5,\n",
    "            validation_split=0.33,\n",
    "            shuffle=\"batch\",\n",
    "            callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 95.22%; Val: 95.03%; Test: 95.02%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test_rgbmean, y_test_rgbmean, verbose=0)\n",
    "print(\"Train: %.2f%%; Val: %.2f%%; Test: %.2f%%\" % \n",
    "      (np.max(history.history['acc'])*100, np.max(history.history['val_acc'])*100, scores[1]*100)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(output_path + \"cifar_model_inception_v1_95.02.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(output_path + \"cifar_weight_inception_v1_95.02.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_file = open(output_path + 'cifar_model_inception_v1_95.02.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(output_path + \"cifar_weight_inception_v1_95.02.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
