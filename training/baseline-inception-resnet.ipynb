{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.constraints import maxnorm\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import concatenate, add, Lambda\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.callbacks import TensorBoard\n",
    "import keras.backend as K\n",
    "\n",
    "import numpy as np \n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import TrainingMonitor\n",
    "from helpers import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = \"../output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_train = h5py.File(\"../input/datasets/cifar_rgbmean_train.hdf5\")\n",
    "db_test = h5py.File(\"../input/datasets/cifar_rgbmean_test.hdf5\")\n",
    "\n",
    "x_train_rgbmean = db_train[\"images\"][:].astype('float32')\n",
    "x_test_rgbmean = db_test[\"images\"][:].astype('float32')\n",
    "\n",
    "mean = np.mean(x_train_rgbmean, axis=0)\n",
    "x_train_rgbmean -= mean\n",
    "x_test_rgbmean -= mean\n",
    "\n",
    "y_train_rgbmean = db_train[\"labels\"][:]\n",
    "y_test_rgbmean = db_test[\"labels\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class INCEPTION_RESNET:\n",
    "    @staticmethod\n",
    "    def conv_module(x, num_filter, size_filter, stride, reg, name=None):\n",
    "        (convName, bnName, actName) = (None, None, None)\n",
    "        if name is not None:\n",
    "            convName = name + \"_conv\"\n",
    "            bnName = name + \"_bn\"\n",
    "            actName = name + \"_act\"\n",
    "            \n",
    "        x = Conv2D(num_filter, size_filter, strides=stride, padding=\"same\", kernel_regularizer=l2(reg), name=convName)(x)\n",
    "        x = Activation(\"relu\", name=actName)(x)\n",
    "        x = BatchNormalization(axis=-1, name=bnName)(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def inception_module(x, num1x1, num3x3Reduce, num3x3, num5x5Reduce, num5x5, num1x1Proj, reg, stage):\n",
    "        shortcut = x\n",
    "        \n",
    "        first = INCEPTION_RESNET.conv_module(x, num1x1, 1, 1, reg, name=stage + \"_1x1\")\n",
    "\n",
    "        second = INCEPTION_RESNET.conv_module(x, num3x3Reduce, 1, 1, reg, name=stage + \"_3x3_1\")\n",
    "        second = INCEPTION_RESNET.conv_module(second, num3x3, 3, 1, reg, name=stage + \"_3x3_2\")\n",
    "\n",
    "        third = INCEPTION_RESNET.conv_module(x, num5x5Reduce, 1, 1, reg, name=stage + \"_5x5_1\")\n",
    "        third = INCEPTION_RESNET.conv_module(third, num5x5, 5, 1, reg, name=stage + \"_5x5_2\")\n",
    "\n",
    "        fourth = MaxPooling2D(3, strides=1, padding=\"same\", name=stage + \"_pool_1\")(x)\n",
    "        fourth = INCEPTION_RESNET.conv_module(fourth, num1x1Proj, 1, 1, reg, name=stage + \"_pool_2\")\n",
    "\n",
    "        mixed = concatenate([first, second, third, fourth], axis=-1, name=stage + \"_mixed\")\n",
    "        \n",
    "        shortcut = Conv2D((num1x1 + num3x3 + num5x5 + num1x1Proj), \n",
    "                          1, strides=1, use_bias=False, kernel_regularizer=l2(reg))(x)\n",
    "        \n",
    "        x = add([mixed, shortcut])\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def build(include_top=True, reg=0.0005):\n",
    "        inputs = Input(shape=x_train_rgbmean.shape[1:])\n",
    "        \n",
    "        x = INCEPTION_RESNET.inception_module(inputs, 32, 32, 32, 16, 16, 32, reg, \"block1\")\n",
    "        x = INCEPTION_RESNET.inception_module(x, 64, 64, 64, 32, 32, 64, reg, \"block2\")\n",
    "        x = INCEPTION_RESNET.inception_module(x, 64, 64, 64, 32, 32, 64, reg, \"block3\")\n",
    "        \n",
    "        if include_top:\n",
    "            x = AveragePooling2D((8, 8))(x)\n",
    "            x = Dropout(0.5, name=\"do\")(x)\n",
    "            x = Flatten(name=\"flatten\")(x)\n",
    "            x = Dense(10, kernel_regularizer=l2(reg), name=\"labels\")(x)\n",
    "            x = Activation(\"softmax\", name=\"softmax\")(x)\n",
    "            \n",
    "        model = Model(inputs, x)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = INCEPTION_RESNET.build(include_top=True, reg=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_3x3_1_conv (Conv2D)      (None, 32, 32, 32)   128         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_5x5_1_conv (Conv2D)      (None, 32, 32, 16)   64          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_3x3_1_act (Activation)   (None, 32, 32, 32)   0           block1_3x3_1_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1_5x5_1_act (Activation)   (None, 32, 32, 16)   0           block1_5x5_1_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1_3x3_1_bn (BatchNormaliza (None, 32, 32, 32)   128         block1_3x3_1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_5x5_1_bn (BatchNormaliza (None, 32, 32, 16)   64          block1_5x5_1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool_1 (MaxPooling2D)    (None, 32, 32, 3)    0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_1x1_conv (Conv2D)        (None, 32, 32, 32)   128         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_3x3_2_conv (Conv2D)      (None, 32, 32, 32)   9248        block1_3x3_1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_5x5_2_conv (Conv2D)      (None, 32, 32, 16)   6416        block1_5x5_1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool_2_conv (Conv2D)     (None, 32, 32, 32)   128         block1_pool_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block1_1x1_act (Activation)     (None, 32, 32, 32)   0           block1_1x1_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_3x3_2_act (Activation)   (None, 32, 32, 32)   0           block1_3x3_2_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1_5x5_2_act (Activation)   (None, 32, 32, 16)   0           block1_5x5_2_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool_2_act (Activation)  (None, 32, 32, 32)   0           block1_pool_2_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1_1x1_bn (BatchNormalizati (None, 32, 32, 32)   128         block1_1x1_act[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1_3x3_2_bn (BatchNormaliza (None, 32, 32, 32)   128         block1_3x3_2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_5x5_2_bn (BatchNormaliza (None, 32, 32, 16)   64          block1_5x5_2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool_2_bn (BatchNormaliz (None, 32, 32, 32)   128         block1_pool_2_act[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1_mixed (Concatenate)      (None, 32, 32, 112)  0           block1_1x1_bn[0][0]              \n",
      "                                                                 block1_3x3_2_bn[0][0]            \n",
      "                                                                 block1_5x5_2_bn[0][0]            \n",
      "                                                                 block1_pool_2_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 112)  336         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 32, 32, 112)  0           block1_mixed[0][0]               \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block2_3x3_1_conv (Conv2D)      (None, 32, 32, 64)   7232        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block2_5x5_1_conv (Conv2D)      (None, 32, 32, 32)   3616        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block2_3x3_1_act (Activation)   (None, 32, 32, 64)   0           block2_3x3_1_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2_5x5_1_act (Activation)   (None, 32, 32, 32)   0           block2_5x5_1_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2_3x3_1_bn (BatchNormaliza (None, 32, 32, 64)   256         block2_3x3_1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_5x5_1_bn (BatchNormaliza (None, 32, 32, 32)   128         block2_5x5_1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool_1 (MaxPooling2D)    (None, 32, 32, 112)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block2_1x1_conv (Conv2D)        (None, 32, 32, 64)   7232        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block2_3x3_2_conv (Conv2D)      (None, 32, 32, 64)   36928       block2_3x3_1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_5x5_2_conv (Conv2D)      (None, 32, 32, 32)   25632       block2_5x5_1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool_2_conv (Conv2D)     (None, 32, 32, 64)   7232        block2_pool_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block2_1x1_act (Activation)     (None, 32, 32, 64)   0           block2_1x1_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_3x3_2_act (Activation)   (None, 32, 32, 64)   0           block2_3x3_2_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2_5x5_2_act (Activation)   (None, 32, 32, 32)   0           block2_5x5_2_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool_2_act (Activation)  (None, 32, 32, 64)   0           block2_pool_2_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_1x1_bn (BatchNormalizati (None, 32, 32, 64)   256         block2_1x1_act[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2_3x3_2_bn (BatchNormaliza (None, 32, 32, 64)   256         block2_3x3_2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_5x5_2_bn (BatchNormaliza (None, 32, 32, 32)   128         block2_5x5_2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool_2_bn (BatchNormaliz (None, 32, 32, 64)   256         block2_pool_2_act[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2_mixed (Concatenate)      (None, 32, 32, 224)  0           block2_1x1_bn[0][0]              \n",
      "                                                                 block2_3x3_2_bn[0][0]            \n",
      "                                                                 block2_5x5_2_bn[0][0]            \n",
      "                                                                 block2_pool_2_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 224)  25088       add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 32, 32, 224)  0           block2_mixed[0][0]               \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block3_3x3_1_conv (Conv2D)      (None, 32, 32, 64)   14400       add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_5x5_1_conv (Conv2D)      (None, 32, 32, 32)   7200        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_3x3_1_act (Activation)   (None, 32, 32, 64)   0           block3_3x3_1_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3_5x5_1_act (Activation)   (None, 32, 32, 32)   0           block3_5x5_1_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3_3x3_1_bn (BatchNormaliza (None, 32, 32, 64)   256         block3_3x3_1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block3_5x5_1_bn (BatchNormaliza (None, 32, 32, 32)   128         block3_5x5_1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool_1 (MaxPooling2D)    (None, 32, 32, 224)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_1x1_conv (Conv2D)        (None, 32, 32, 64)   14400       add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_3x3_2_conv (Conv2D)      (None, 32, 32, 64)   36928       block3_3x3_1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_5x5_2_conv (Conv2D)      (None, 32, 32, 32)   25632       block3_5x5_1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool_2_conv (Conv2D)     (None, 32, 32, 64)   14400       block3_pool_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block3_1x1_act (Activation)     (None, 32, 32, 64)   0           block3_1x1_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_3x3_2_act (Activation)   (None, 32, 32, 64)   0           block3_3x3_2_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3_5x5_2_act (Activation)   (None, 32, 32, 32)   0           block3_5x5_2_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool_2_act (Activation)  (None, 32, 32, 64)   0           block3_pool_2_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_1x1_bn (BatchNormalizati (None, 32, 32, 64)   256         block3_1x1_act[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3_3x3_2_bn (BatchNormaliza (None, 32, 32, 64)   256         block3_3x3_2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block3_5x5_2_bn (BatchNormaliza (None, 32, 32, 32)   128         block3_5x5_2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool_2_bn (BatchNormaliz (None, 32, 32, 64)   256         block3_pool_2_act[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3_mixed (Concatenate)      (None, 32, 32, 224)  0           block3_1x1_bn[0][0]              \n",
      "                                                                 block3_3x3_2_bn[0][0]            \n",
      "                                                                 block3_5x5_2_bn[0][0]            \n",
      "                                                                 block3_pool_2_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 224)  50176       add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 32, 32, 224)  0           block3_mixed[0][0]               \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 4, 4, 224)    0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "do (Dropout)                    (None, 4, 4, 224)    0           average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3584)         0           do[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "labels (Dense)                  (None, 10)           35850       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 10)           0           labels[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 331,594\n",
      "Trainable params: 329,994\n",
      "Non-trainable params: 1,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='models/baseline-inception-resnet.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2604\n"
     ]
    }
   ],
   "source": [
    "#filepath=output_path + \"progress/inception-weights-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "print(os.getpid())\n",
    "filepath=output_path + \"progress/inception-resnet-weights-best.hdf5\"\n",
    "MC = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "figPath = os.path.sep.join([output_path, \"monitor/{}.png\".format(os.getpid())])\n",
    "jsonPath = os.path.sep.join([output_path, \"monitor/{}.json\".format(os.getpid())])\n",
    "TM = TrainingMonitor(figPath, jsonPath=jsonPath, startAt=10)\n",
    "\n",
    "RLR = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [MC, TM, RLR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33500 samples, validate on 16500 samples\n",
      "Epoch 1/20\n",
      "33500/33500 [==============================] - 169s 5ms/step - loss: 0.1883 - acc: 0.9443 - val_loss: 0.1928 - val_acc: 0.9427\n",
      "Epoch 2/20\n",
      "33500/33500 [==============================] - 185s 6ms/step - loss: 0.1844 - acc: 0.9452 - val_loss: 0.1823 - val_acc: 0.9459\n",
      "Epoch 3/20\n",
      "33500/33500 [==============================] - 184s 5ms/step - loss: 0.1812 - acc: 0.9459 - val_loss: 0.1880 - val_acc: 0.9434\n",
      "Epoch 4/20\n",
      "33500/33500 [==============================] - 185s 6ms/step - loss: 0.1788 - acc: 0.9468 - val_loss: 0.1929 - val_acc: 0.9412\n",
      "Epoch 5/20\n",
      "33500/33500 [==============================] - 184s 5ms/step - loss: 0.1757 - acc: 0.9479 - val_loss: 0.1920 - val_acc: 0.9421\n",
      "Epoch 6/20\n",
      "33500/33500 [==============================] - 185s 6ms/step - loss: 0.1729 - acc: 0.9486 - val_loss: 0.1876 - val_acc: 0.9433\n",
      "Epoch 7/20\n",
      "33500/33500 [==============================] - 185s 6ms/step - loss: 0.1701 - acc: 0.9504 - val_loss: 0.1847 - val_acc: 0.9441\n",
      "Epoch 8/20\n",
      "33500/33500 [==============================] - 185s 6ms/step - loss: 0.1699 - acc: 0.9499 - val_loss: 0.1872 - val_acc: 0.9429\n",
      "Epoch 9/20\n",
      "33500/33500 [==============================] - 184s 6ms/step - loss: 0.1430 - acc: 0.9596 - val_loss: 0.1435 - val_acc: 0.9577\n",
      "Epoch 10/20\n",
      "33500/33500 [==============================] - 184s 5ms/step - loss: 0.1315 - acc: 0.9618 - val_loss: 0.1375 - val_acc: 0.9589\n",
      "Epoch 11/20\n",
      "33500/33500 [==============================] - 185s 6ms/step - loss: 0.1271 - acc: 0.9631 - val_loss: 0.1342 - val_acc: 0.9595\n",
      "Epoch 12/20\n",
      "33500/33500 [==============================] - 185s 6ms/step - loss: 0.1235 - acc: 0.9641 - val_loss: 0.1371 - val_acc: 0.9581\n",
      "Epoch 13/20\n",
      "33500/33500 [==============================] - 185s 6ms/step - loss: 0.1212 - acc: 0.9648 - val_loss: 0.1373 - val_acc: 0.9577\n",
      "Epoch 14/20\n",
      "33500/33500 [==============================] - 185s 6ms/step - loss: 0.1187 - acc: 0.9655 - val_loss: 0.1317 - val_acc: 0.9598\n",
      "Epoch 15/20\n",
      "33500/33500 [==============================] - 185s 6ms/step - loss: 0.1167 - acc: 0.9663 - val_loss: 0.1283 - val_acc: 0.9615\n",
      "Epoch 16/20\n",
      "33500/33500 [==============================] - 185s 6ms/step - loss: 0.1150 - acc: 0.9669 - val_loss: 0.1304 - val_acc: 0.9607\n",
      "Epoch 17/20\n",
      "33500/33500 [==============================] - 186s 6ms/step - loss: 0.1131 - acc: 0.9675 - val_loss: 0.1331 - val_acc: 0.9597\n",
      "Epoch 18/20\n",
      "33500/33500 [==============================] - 185s 6ms/step - loss: 0.1117 - acc: 0.9682 - val_loss: 0.1341 - val_acc: 0.9590\n",
      "Epoch 19/20\n",
      "33500/33500 [==============================] - 186s 6ms/step - loss: 0.1111 - acc: 0.9687 - val_loss: 0.1292 - val_acc: 0.9610\n",
      "Epoch 20/20\n",
      "33500/33500 [==============================] - 187s 6ms/step - loss: 0.1098 - acc: 0.9689 - val_loss: 0.1324 - val_acc: 0.9601\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_rgbmean, y_train_rgbmean,\n",
    "            batch_size=64,\n",
    "            epochs=20,\n",
    "            validation_split=0.33,\n",
    "            shuffle=\"batch\",\n",
    "            callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 92.19%; Val: 92.19%; Test: 92.23%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test_rgbmean, y_test_rgbmean, verbose=0)\n",
    "print(\"Train: %.2f%%; Val: %.2f%%; Test: %.2f%%\" % \n",
    "      (np.max(history.history['acc'])*100, np.max(history.history['val_acc'])*100, scores[1]*100)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(output_path + \"cifar_model_inception_resnet_96.01.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(output_path + \"cifar_weight_inception_resnet_96.01.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
