{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import progressbar \n",
    "import random \n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from helpers import HDF5DatasetWriter\n",
    "from helpers import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path_train = \"../input/data/cifar/vgg16_features_train.hdf5\"\n",
    "output_path_test = \"../input/data/cifar/vgg16_features_test.hdf5\"\n",
    "batch_size = 32\n",
    "buffer_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_name = np.array([\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_feature(model, x, y, output_path, batch_size = 32, buffer_size = 1000):\n",
    "    dataset = HDF5DatasetWriter((x.shape[0], 512 * 7 * 7), (y.shape[0], 10), output_path, dataKey=\"features\",  bufSize = buffer_size)\n",
    "    dataset.storeClassLabels(labels_name)\n",
    "    \n",
    "    lb = LabelBinarizer()\n",
    "    y = lb.fit_transform(y)\n",
    "    \n",
    "    widgets = [\"Extracting Features: \", progressbar.Percentage(), \" \", progressbar.Bar(), \" \", progressbar.ETA()]\n",
    "    pbar = progressbar.ProgressBar(maxval=x.shape[0], widgets=widgets).start()\n",
    "\n",
    "    for i in np.arange(0, x.shape[0], batch_size):\n",
    "        batchData = x[i:i + batch_size]\n",
    "        batchLabels = y[i:i + batch_size]\n",
    "        batchImages = []\n",
    "        for (j, image) in enumerate(batchData):\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "            image = img_to_array(image)\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "            image = imagenet_utils.preprocess_input(image) / 255.0\n",
    "            batchImages.append(image)\n",
    "        batchImages = np.vstack(batchImages)\n",
    "        features = model.predict(batchImages, batch_size=batch_size)\n",
    "        features = features.reshape((features.shape[0], 512 * 7 * 7))\n",
    "        dataset.add(features, batchLabels)\n",
    "        pbar.update(i)\n",
    "    dataset.close()\n",
    "    pbar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100% |#####################################| Time: 0:13:43\n"
     ]
    }
   ],
   "source": [
    "extract_feature(model, x_train, y_train, output_path_train, batch_size = 32, buffer_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100% |#####################################| Time: 0:02:22\n"
     ]
    }
   ],
   "source": [
    "extract_feature(model, x_test, y_test, output_path_test, batch_size = 32, buffer_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['features', 'label_names', 'labels']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "db = h5py.File(output_path_train)\n",
    "list(db.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
